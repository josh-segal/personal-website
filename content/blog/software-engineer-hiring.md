### **Opening the Numbers**

Would you believe me if I told you 40% of recruiters ghost software engineer candidates? If you did, you would be right… if it were still 2020. Today, it’s [80%](https://www.hrdive.com/news/hiring-managers-responsive-applicants/716173/).

Last year, I submitted over 400 applications for internships. The whole time, I was torn between building projects I actually cared about and enduring the soul-crushing grind of LeetCode prep. (But don’t worry, if you just [memorize LeetCode problems](https://kylelix7.github.io/How-I-leetcode-for-6-months-and-land-a-job-at-Amazon/) for 6 months straight you too can get a Big Tech job!) In the end, I received just four interviews and one offer. 

The numbers are brutal, and they’re not just a personal frustration; they’re a sign that the hiring culture itself is in crisis. Hiring at scale has [fallen prey to Goodhart’s Law](https://dev.to/dbc2201/breaking-the-leetcode-loop-how-goodharts-law-exposes-the-pitfalls-of-mindless-coding-grinds-26hg), relying on pattern-matching credentials and contrived challenges instead of actual engineering talent.

### “Hire Builders, Not Test Takers”

What if we stopped asking candidates to solve [toy problems](http://www.catb.org/jargon/html/T/toy-problem.html) and started asking how they solve real engineering problems?

That question lies at the heart of two new startups redefining how technical hiring works: [Byteboard](https://www.byteboard.dev/), a platform spun out of [Google’s internal R&D](https://techcrunch.com/2019/07/17/googles-area-120-launches-byteboard-to-improve-technical-interviews/) team, and [CodeBrain](https://www.rounds.so/), the brainchild of founders [Rafay Syed and Fardeen Khimani](https://www.rounds.so/about). Take a look at their landing pages and the message is clear. Byteboard boldly states “**Hire builders, not test takers**” and CodeBrain directly stamps “**Uses AI to code**” as one of the three primary skills they revere. 

Unlike traditional interviews, which too often rely on [outdated whiteboard theatrics](https://coderpad.io/blog/interviewing/whiteboard-interview-guide/)^1^ and recall under pressure, Byteboard and CodeBrain challenge candidates in environments that simulate the real job and not only allow, but *encourage*^2^ the use of AI tools.

Byteboard throws out the standard LeetCode gauntlet in favor of project-based evaluations. Candidates work through [realistic engineering scenarios](https://www.byteboard.dev/core-eval) in a way that mirrors a day on the job. At companies like Lyft and Figma, Byteboard [shortened time-to-hire](https://www.byteboard.dev/case-study/figma) by over a week while also increasing underrepresented candidate hiring numbers. This shift is critical. Traditional coding interviews, similar to the SAT, [often measure access to resources](https://districtadministration.com/article/new-sat-data-highlights-the-deep-inequality-at-the-heart-of-american-education/) more than actual engineering ability. Byteboard has shown that by focusing on contextual, real-world problem solving, companies are creating fairer *and* faster hiring processes.

CodeBrain takes this paradigm a step further; rather than ignore the AI tools developers actually use, they built them into the test. Candidates are judged not on memorization, but on how well they wield modern tools to solve complex problems. It’s a radical inversion of the "no AI allowed" rulebook that so many interviewers still cling to—and is a stark contrast to other, less fair solutions like [Interview Coder](https://www.cnbc.com/2025/03/09/google-ai-interview-coder-cheat.html).

Together, Byteboard and CodeBrain push us toward a more honest question: *How do you use resources to build*, and not, *what do you know off the top of your head?* Using your resources to build is the skill companies actually need, and until now, haven’t really tested for. These platforms don’t just replicate old tests with new tools; they model what a human-AI partnership can actually look like.

### **The Cautionary Side**

Byteboard and CodeBrain pave a future where the hiring process is more transparent, fair, and attuned to actual engineering work; however, there’s a cautionary side to all this innovation. As these AI tools become more prevalent, we can’t lose sight of what happens when algorithms start to not just augment, but replace human judgment. As demonstrated within Amazon’s [colossal AI resume screener failure](https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/), when human judgment exits the loop entirely, fairness becomes a function of historical bias.

We need to redesign the whole process so that algorithms and human judgment work together; We all—not just recruiters and engineers, but humans in general—need to be aware of the tradeoffs these tools carry with them so that we don’t [cognitively offload ourselves](https://www.mdpi.com/2075-4698/15/1/6) off an intellectual cliff.^3^

### **A Final Note**

For an industry obsessed with user experience, tech has somehow made interviews the worst product it ships.

The best teams build, test, iterate, and listen; Interviews should do the same. Tools like Byteboard and CodeBrain are a start—not because they’re digital, but because they’re designed. They don’t just upgrade the interface, they ask *what should this experience actually measure?* *Who does it serve?* *What does it leave behind?*

The future of hiring—and software for that matter—isn’t about humans versus algorithms. It’s about creating a system with the efficiency and reach of AI, and the empathy and nuance that only humans can bring.

It’s time for tech to ship something better.

---
^1^Whiteboard interviews go as far back as the 1980’s when it was literally too expensive and heavy to bring portable computers to candidate interviews.

^2^CodeBrain has an *embedded* link to ChatGPT *inside* their assessment environment.

^3^Addendum: New research by MIT finding [cognitive debt](https://www.media.mit.edu/publications/your-brain-on-chatgpt/) with LLM usage.